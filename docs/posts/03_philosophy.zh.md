# HexFormer：給工程師看的白話解釋

> 如果 Transformer 架構是語言理解的引擎，
> 那麼 HexFormer 就是讓語義可以「結構化運轉」的語義作業系統。

---

## TL;DR

- 我們不再用 token 當作語言模型的輸入單位，而是用 **8-bit（byte）作為語義基本單元**。
- 我們不把語義表示當作浮點矩陣 embedding，而是組成 **2ⁿ 結構**（像是 6-bit 對應 64 卦），變成可以計算與推理的「語義符號」。
- 然後把這兩層結構裝進 Swin / BERT 架構裡，還能對應硬體（SIMD / TensorCore）加速。

簡而言之：

> **語義的本質可以歸結為 0 和 1 的組合。8 位元提供了語義框架的基本單位，而 2ⁿ 結構則對應語義層級的組合與變化空間。這種設計不僅具備數學邏輯的一致性，也具備運算結構的可擴展性與可解釋性。**

---

## 核心概念

### 🧱 8-bit 是什麼？

- 每一個語義最小單位用 1 byte 表示（0~255）
- 這些 byte 可以：
  - 被嵌入成向量（byte embedding）
  - 做位操作（如 XOR、SHIFT）來做語義運算
  - 直接跑進 attention 結構裡面訓練（不用再經過 tokenizer）

這就像是在跑「語義的位元操作」，而不是在跑黑箱的 token embedding。

### 🧠 2ⁿ 結構是什麼？

- 把多個 byte（比如 6 個）組合起來，就能形成一個 **語義符號單元**（symbolic unit）
- 這些符號對應的是 2ⁿ 個語義狀態（比如 2⁶ = 64 卦）
- 每個符號都有固定位置的 bit 意義（比如哪個位代表情緒、角色、調性等等）

這樣做可以幫我們：
- 建立語義層級結構（symbol hierarchy）
- 做語義遷移（爻變 = bit flip）
- 對應模型內的注意力調整與計算路由

> ✅ 在 HexFormer 架構中，語義不再是學出來的 embedding，而是「可解構、可組合、可變化」的位元排列。
> **語義的本質被還原為二進制的組合與變化，並透過位元框架與層級推理機制實現語境掌控與語意流動。**

### 🔁 怎麼跟 Swin/BERT 結合？

- **Byte-level 嵌入**：將 byte 序列進行嵌入，輸入 Transformer 模型
- **符號控制 Attention**：由 2ⁿ 的符號決定哪些 window attention 啟用（mask）
- **位元遮罩訓練**：可以隨機遮罩特定位元，訓練模型進行語義重建

這一切都能對應到現有的 Swin 變種、BERT 預訓練任務、甚至多模態解碼器。

---

## 🧨 為什麼 token 其實是語義浪費？

傳統 token-based 模型的處理方式是：

```
文字 → tokenizer → token index → embedding vector → attention 計算
```

但這種設計有幾個問題：

- Token 只是個 ID，背後沒有語義結構，
- token 索引的 bit pattern 沒有意義（例如 token 25 = 01010101 並不代表什麼）
- 許多 embedding 是空白的（vocab 幾萬，常用幾千）
- 同一 token 有時代表一個詞、有時是一個片段，無法一致建模
- 訓練時嵌入向量是黑箱學出來的，不可解釋、難追蹤

而 HexFormer 告訴我們：

> 不如直接用 byte！因為：
> - 每一 byte（8-bit）就是固定長度的語義單位
> - 每一位元都可以用來表示語義 feature（位置、語氣、情緒…）
> - 不用 token embedding matrix，直接 byte embedding 就能訓練
> - 還能做位元邏輯運算、遮罩、注意力路由

---

## 💡 簡單對比

| 項目 | Token-based 模型 | HexFormer 模型 |
|------|------------------|----------------|
| 單位單元 | Token | Byte (8-bit) |
| 表示結構 | 隱含語義向量 | 顯式結構 + 位元操作 |
| 空間效率 | 浪費（embedding matrix 大） | 高效（256 byte + 組合） |
| 推理能力 | 嵌入學出來的黑箱語義 | 結構驅動的顯式語義 |
| 表示一致性 | token 長度變異大 | 固定 byte block |
| 操作方式 | 無邏輯 | 位操作（翻轉、遮罩、XOR） |

---

## 🧬 為什麼這樣設計比較香？

- ✅ **語義結構可追蹤**：每個 bit 都有語義意義（可視化、debug 方便）
- ✅ **模型更輕巧**：8-bit 計算降低 FLOPs 與能耗
- ✅ **推理可控**：每次 bit flip（爻變）代表語義上的「轉折」
- ✅ **多模態更穩**：控制得好，產出的圖像、聲音、文本都能維持語義一致性
- ✅ **根本不是壓縮，而是重構**：
  - 別人是 Q4、Q8 壓縮模型，我們是直接從 Q1 架構出發來設計
  - 別人是用浮點數壓縮，我們是從 8-bit 原生起步 + 符號結構控制

---

## 📘 結語：

HexFormer 的設計邏輯可以歸納為：

> 「用 8 位元作為語義的基本框架，透過位元組合（0 和 1）來構造語義結構，並以 2ⁿ 層級組合方式建立語境與推理的層次。這使得語義表示與運算結構高度一致，具備良好的可控性、可擴展性與硬體適配性。」

它不是取代 Transformer，而是重新設計了語義的表示方式與運算單位，並與現有架構相容。

📦 GitHub: https://github.com/woolkingx/HexFormer

